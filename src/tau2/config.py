# SIMULATION
DEFAULT_MAX_STEPS = 200
DEFAULT_MAX_ERRORS = 10
DEFAULT_SEED = 300
DEFAULT_MAX_CONCURRENCY = 3
DEFAULT_NUM_TRIALS = 1
DEFAULT_SAVE_TO = None
DEFAULT_LOG_LEVEL = "ERROR"

# LLM DEBUG LOGGING
DEFAULT_LLM_LOG_MODE = "latest"  # Options: "all", "latest"

# LLM
DEFAULT_AGENT_IMPLEMENTATION = "llm_agent"
DEFAULT_USER_IMPLEMENTATION = "user_simulator"
DEFAULT_LLM_AGENT = "gpt-4.1-2025-04-14"
DEFAULT_LLM_USER = "gpt-4.1-2025-04-14"
DEFAULT_LLM_TEMPERATURE_AGENT = 0.0
DEFAULT_LLM_TEMPERATURE_USER = 0.0
DEFAULT_LLM_ARGS_AGENT = {"temperature": DEFAULT_LLM_TEMPERATURE_AGENT}
DEFAULT_LLM_ARGS_USER = {"temperature": DEFAULT_LLM_TEMPERATURE_USER}

DEFAULT_LLM_NL_ASSERTIONS = "gpt-4.1-2025-04-14"
DEFAULT_LLM_NL_ASSERTIONS_TEMPERATURE = 0.0
DEFAULT_LLM_NL_ASSERTIONS_ARGS = {"temperature": DEFAULT_LLM_NL_ASSERTIONS_TEMPERATURE}

DEFAULT_LLM_ENV_INTERFACE = "gpt-4.1-2025-04-14"
DEFAULT_LLM_ENV_INTERFACE_TEMPERATURE = 0.0
DEFAULT_LLM_ENV_INTERFACE_ARGS = {"temperature": DEFAULT_LLM_ENV_INTERFACE_TEMPERATURE}

DEFAULT_LLM_EVAL_USER_SIMULATOR = "claude-opus-4-5"

# LITELLM
DEFAULT_MAX_RETRIES = 3
LLM_CACHE_ENABLED = False
DEFAULT_LLM_CACHE_TYPE = "redis"

# RETRY CONFIGURATION
DEFAULT_RETRY_ATTEMPTS = 3
DEFAULT_RETRY_MIN_WAIT = 1.0  # seconds
DEFAULT_RETRY_MAX_WAIT = 10.0  # seconds
DEFAULT_RETRY_MULTIPLIER = 1.0  # exponential backoff multiplier

# REDIS CACHE
REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_PASSWORD = ""
REDIS_PREFIX = "tau2"
REDIS_CACHE_VERSION = "v1"
REDIS_CACHE_TTL = 60 * 60 * 24 * 30

# LANGFUSE
USE_LANGFUSE = False  # If True, make sure all the env variables are set for langfuse.

# API
API_PORT = 8000

# VOICE (legacy - kept for backwards compatibility)
DEFAULT_VOICE_ENABLED = False
DEFAULT_VOICE_SYNTHESIS_PROVIDER = "elevenlabs"
DEFAULT_VOICE_TRANSCRIPTION_MODEL = "nova-3"
DEFAULT_VOICE_MODEL = "eleven_v3"
# Voice outputs will be stored in DATA_DIR / "simulations" / "<timestamp_domain_agent_user>" / "voice" / "sim_<simulation_id>" / "turn_<turn_uuid>" /

# STREAMING (legacy - kept for backwards compatibility)
DEFAULT_TEXT_STREAMING_CHUNK_BY = "words"
DEFAULT_TEXT_STREAMING_CHUNK_SIZE = 1
DEFAULT_TEXT_STREAMING_CONFIG = {
    "chunk_by": DEFAULT_TEXT_STREAMING_CHUNK_BY,
    "chunk_size": DEFAULT_TEXT_STREAMING_CHUNK_SIZE,
}

# AUDIO NATIVE (Full-duplex voice using DiscreteTimeAudioNativeAgent)
# Agent and user implementations for audio-native mode
DEFAULT_AUDIO_NATIVE_AGENT_IMPLEMENTATION = "discrete_time_audio_native_agent"
DEFAULT_AUDIO_NATIVE_USER_IMPLEMENTATION = "voice_streaming_user_simulator"

# Timing configuration
DEFAULT_TICK_DURATION_SECONDS = 0.20  # 200ms ticks
DEFAULT_MAX_STEPS_SECONDS = 600  # 10 minutes max conversation duration

# Audio configuration
DEFAULT_PCM_SAMPLE_RATE = 16000  # User simulator synthesis rate
DEFAULT_TELEPHONY_RATE = 8000  # API/agent rate (8kHz μ-law, 1 byte/sample)
TELEPHONY_ULAW_SILENCE = b"\x7f"  # μ-law silence byte

# Turn-taking thresholds (in seconds, converted to ticks at runtime)
DEFAULT_WAIT_TO_RESPOND_THRESHOLD_OTHER_SECONDS = 1.0
DEFAULT_WAIT_TO_RESPOND_THRESHOLD_SELF_SECONDS = 5.0
DEFAULT_YIELD_THRESHOLD_WHEN_INTERRUPTED_SECONDS = 1.0
DEFAULT_YIELD_THRESHOLD_WHEN_INTERRUPTING_SECONDS = 5.0
DEFAULT_INTERRUPTION_CHECK_INTERVAL_SECONDS = 2.0
DEFAULT_INTEGRATION_DURATION_SECONDS = 0.5
DEFAULT_SILENCE_ANNOTATION_THRESHOLD_SECONDS = 4.0
DEFAULT_BACKCHANNEL_MIN_THRESHOLD_SECONDS = (
    3.0  # 2 seconds minimum before backchanneling
)
DEFAULT_BACKCHANNEL_MAX_THRESHOLD_SECONDS = 12.0  # 6 seconds max - force backchannel
DEFAULT_BACKCHANNEL_POISSON_RATE = 1.0 / 10.0  # ~1 event per 10 seconds
DEFAULT_USE_LLM_BACKCHANNEL = True  # Use LLM-based backchannel policy (vs Poisson)

# Agent behavior
DEFAULT_BUFFER_UNTIL_COMPLETE = True
DEFAULT_FAST_FORWARD_MODE = True
DEFAULT_SEND_AUDIO_INSTANT = True

# Speech complexity for user simulator
DEFAULT_SPEECH_COMPLEXITY = "regular"  # Options: "control", "regular"

# OpenAI Realtime API configuration
DEFAULT_OPENAI_REALTIME_MODEL = "gpt-realtime-2025-08-28"
DEFAULT_OPENAI_REALTIME_BASE_URL = "wss://api.openai.com/v1/realtime"
DEFAULT_OPENAI_VAD_THRESHOLD_LOW = (
    0.2  # Audio level threshold (0.0-1.0). OpenAI default is 0.5.
)
DEFAULT_OPENAI_VAD_THRESHOLD_DEFAULT = 0.5
DEFAULT_OPENAI_VAD_THRESHOLD = DEFAULT_OPENAI_VAD_THRESHOLD_DEFAULT

# Gemini Live API configuration
DEFAULT_GEMINI_MODEL = "models/gemini-live-2.5-flash-native-audio"
# For Vertex AI, use model without "models/" prefix
# See: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference
DEFAULT_GEMINI_MODEL_VERTEX = "gemini-live-2.5-flash-native-audio"
DEFAULT_GEMINI_VOICE = "Zephyr"
DEFAULT_GEMINI_LOCATION = "us-central1"

# xAI Grok Voice Agent API configuration
DEFAULT_XAI_REALTIME_BASE_URL = "wss://api.x.ai/v1/realtime"
DEFAULT_XAI_VOICE = "Ara"  # Options: Ara, Rex, Sal, Eve, Leo
DEFAULT_XAI_MODEL = "grok-3"  # Placeholder - xAI may update model names

# Amazon Nova Sonic API configuration
DEFAULT_NOVA_MODEL = "amazon.nova-2-sonic-v1:0"
DEFAULT_NOVA_VOICE = "tiffany"  # Options: matthew, tiffany, amy
DEFAULT_NOVA_REGION = "us-east-1"

# Qwen Omni Flash Realtime API configuration
DEFAULT_QWEN_MODEL = "qwen3-omni-flash-realtime"
DEFAULT_QWEN_VOICE = "Cherry"

# Deepgram Voice Agent API configuration
# Note: Deepgram is a cascaded system (STT→LLM→TTS), not a native audio model
DEFAULT_DEEPGRAM_STT_MODEL = "nova-3"  # Deepgram STT model
DEFAULT_DEEPGRAM_LLM_PROVIDER = "open_ai"  # LLM provider (open_ai, anthropic, etc.)
DEFAULT_DEEPGRAM_LLM_MODEL = "gpt-5.1"  # LLM used by Deepgram Voice Agent
DEFAULT_DEEPGRAM_TTS_MODEL = "aura-2-thalia-en"  # TTS voice model

# Audio-native provider
DEFAULT_AUDIO_NATIVE_PROVIDER = (
    "openai"  # Options: "openai", "gemini", "xai", "nova", "qwen"
)
DEFAULT_AUDIO_NATIVE_MODELS = {
    "openai": DEFAULT_OPENAI_REALTIME_MODEL,
    "gemini": DEFAULT_GEMINI_MODEL_VERTEX,
    "xai": DEFAULT_XAI_MODEL,
    "nova": DEFAULT_NOVA_MODEL,
    "qwen": DEFAULT_QWEN_MODEL,
    "deepgram": DEFAULT_DEEPGRAM_LLM_MODEL,  # Cascaded: uses LLM model as identifier
}

# Provider type classification
# - "audio_native": Native audio-to-audio models (e.g., OpenAI Realtime, Gemini Live)
# - "cascaded": STT→LLM→TTS pipeline (e.g., Deepgram Voice Agent)
AUDIO_NATIVE_PROVIDER_TYPES = {
    "openai": "audio_native",
    "gemini": "audio_native",
    "xai": "audio_native",
    "nova": "audio_native",
    "qwen": "audio_native",
    "deepgram": "cascaded",
}
# Providers that prefer plain text prompts (no XML tags) by default
# Retry configuration for audio-native tasks
DEFAULT_AUDIO_NATIVE_MAX_RETRIES = 3
DEFAULT_AUDIO_NATIVE_RETRY_DELAY_SECONDS = 5.0

# Provider stall detection
DEFAULT_AUDIO_NATIVE_MAX_INACTIVE_SECONDS = 40.0  # Raise error if no provider activity

# DISPLAY
TERM_DARK_MODE = True
